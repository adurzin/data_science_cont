1. Для чего и в каких случаях полезны различные варианты усреднения для метрик качества классификации:
 micro, macro, weighted?

	Ипользуются для усреднения результатов многоклассовых выборок.
	
	macro просто вычисляет среднее значение двоичных показателей, придавая каждому классу одинаковый вес
	
	weighted учитывает дисбаланс классов, вычисляя среднее значение двоичных показателей, в которых оценка каждого класса взвешивается по его присутствию в истинной выборке данных.
	
	micro дает каждой паре выборка-класс равный вклад в общую метрику (за исключением результата взвешивания выборки).


2. В чём разница между моделями xgboost, lightgbm и catboost или какие их основные особенности?

	CATBoost лучше остальных работает с категориальными функциями, в то время как XGBoost принимает только числовые данные.
	
	XGBoost - алгоритм дерева решений, основанный на методе предварительной сортировки.
	
	Lightgbm - Алгоритм дерева решений на основе гистограммы. Потребляет меньшую память и работает быстрее, чем XGBoost.
	
	